{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Anime Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets, malscraper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Datasets\n",
    "From `AnimeList.csv` get\n",
    " - `anime_ids`: Sorted list of all anime id's. Used as columns of `X` and `prediction`.\n",
    " - `anime_dict`: Dictionary of type {'anime_id': 'anime_title'}. Used to reconstruct anime title from anime id.\n",
    "   \n",
    "From `UserAnimeList.csv` get\n",
    " - `userlist`: List of all usernames. Used as index of `X`.\n",
    " - `X`: Sparse user-item matrix. Load in chunks (see https://datascienceplus.com/processing-huge-dataset-with-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data = datasets.MyAnimeList(extension=\"cleaned\",debug=True,chunksize=1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Prediction\n",
    "Factorize `X` into user-matrix `W` and item-matrix `H` with `sklearn.decomposition.NMF`. Essentially solves:\n",
    "\n",
    "$$ \\underset{W,H}{\\mathrm{argmin}} \\sum_{i,j \\, \\in \\, X} (x_{ij} - w_i^T \\cdot h_j)^2 $$\n",
    "\n",
    "Get row index of USER from `userlist`. Predict ratings via:\n",
    "\n",
    "$$ \\hat{x}_i = \\, w_i^T \\cdot H \\qquad (i = \\text{USER_ID})$$\n",
    "\n",
    "Get prediction for new user via linear regression.\n",
    "\n",
    "\n",
    "Sources: \n",
    "* https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf\n",
    "* https://medium.com/datadriveninvestor/how-to-built-a-recommender-system-rs-616c988d64b2\n",
    "\n",
    "SINGULAR VALUE PROBLEM:\n",
    "* No user must have less than k ranked animes.\n",
    "* No anime must have been ranked less than k times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :  Training Error = 12.940036101686983\n"
     ]
    }
   ],
   "source": [
    "class MatrixFactorization():\n",
    "    \n",
    "    def __init__(self, k, reg):\n",
    "        self.k = k\n",
    "        self.reg = reg\n",
    "\n",
    "        \n",
    "    def fit(self, X, steps):\n",
    "        self.U = np.random.randn(X.shape[0],self.k)\n",
    "        self.V = np.random.randn(X.shape[1],self.k)\n",
    "        self.bu = np.zeros(X.shape[0])\n",
    "        self.bv = np.zeros(X.shape[1])\n",
    "        self.mu = X.data.mean()\n",
    "        self.error = [self.loss(X)]\n",
    "        \n",
    "        print(f\"Iteration 0 :  Training Error = {self.error[-1]}\")\n",
    "        \n",
    "        for t in range(1,steps+1):\n",
    "            sv_errors = 0  # count singular value errors\n",
    "            \n",
    "            # Update V\n",
    "            for j in range(self.V.shape[0]):\n",
    "                ivec = X.getcol(j).nonzero()[0]\n",
    "                matrix_ = self.U[ivec].T.dot(self.U[ivec]) + np.eye(self.k) * self.reg\n",
    "                vector_ = (X[ivec,j].T - self.bu[ivec] - self.bv[j] - self.mu).dot(self.U[ivec]).T\n",
    "                try:\n",
    "                    self.bv[j] = (X[ivec,j].T - self.U[ivec].dot(self.V[j]) - self.bu[ivec] - self.mu).sum()\n",
    "                    self.bv[j] = self.bv[j] / ( len(ivec) + self.reg)\n",
    "                    self.V[j] = np.squeeze(np.linalg.solve(matrix_,vector_))\n",
    "                except np.linalg.LinAlgError: \n",
    "                    sv_errors += 1\n",
    "                    continue\n",
    "\n",
    "            # Update U\n",
    "            for i in range(self.U.shape[0]):\n",
    "                jvec = X.getrow(i).nonzero()[1]\n",
    "                matrix_ = self.V[jvec].T.dot(self.V[jvec]) + np.eye(self.k) * self.reg\n",
    "                vector_ = (X[i,jvec] - self.bu[i] - self.bv[jvec] - self.mu).dot(self.V[jvec]).T\n",
    "                try:\n",
    "                    self.bu[i] = (X[i,jvec] - self.V[ivec].dot(self.U[i]) - self.bv[jvec] - self.mu).sum()\n",
    "                    self.bu[i] = self.bu[i] / ( len(jvec) + self.reg)\n",
    "                    self.U[i] = np.squeeze(np.linalg.solve(matrix_,vector_))\n",
    "                except np.linalg.LinAlgError: \n",
    "                    sv_errors += 1\n",
    "                    continue\n",
    "                \n",
    "            self.error.append(self.loss(X))\n",
    "            \n",
    "            print(f\"Iteration {t} :  Training Error = {self.error[-1]}  SV Errors = {sv_errors}/{self.V.shape[0]+self.U.shape[0]}\")\n",
    "        \n",
    "        self.plot_loss()\n",
    "           \n",
    "            \n",
    "    def loss(self, X):\n",
    "        N = 0.\n",
    "        E = 0.\n",
    "        for j in range(self.V.shape[0]):\n",
    "            ivec = X.getcol(j).nonzero()[0]\n",
    "            xtmp = X[ivec,j].T\n",
    "            xhat = self.U[ivec].dot(self.V[j].T) + self.bu[ivec] + self.bv[j] + self.mu\n",
    "            resd = xtmp - xhat\n",
    "            E += resd.dot(resd.T)\n",
    "            N += len(ivec)\n",
    "        return E[0,0] / N\n",
    "    \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.error,color=\"C0\", label=\"Training Error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "model = MatrixFactorization(k=10, reg=20.)\n",
    "model.fit(data.X,steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0:  min : Ace wo Nerae!  max : Elfen Lied\n",
      "Feature 1:  min : Elfen Lied  max : Junjou Romantica\n",
      "Feature 2:  min : Naruto: Shippuuden  max : Aria The Origination\n",
      "Feature 3:  min : Boku no Pico  max : Steins;Gate\n",
      "Feature 4:  min : Bleach Movie 2: The DiamondDust Rebellion - Mou Hitotsu no Hyourinmaru  max : High School DxD BorN\n",
      "Feature 5:  min : School Days  max : Crayon Shin-chan\n",
      "Feature 6:  min : FLCL  max : Isekai wa Smartphone to Tomo ni.\n",
      "Feature 7:  min : Umineko no Naku Koro ni  max : Ghost in the Shell\n",
      "Feature 8:  min : Pico to Chico  max : One Piece\n",
      "Feature 9:  min : Loveless  max : Higurashi no Naku Koro ni Kira\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    jmax = model.V[:,k].argmax()\n",
    "    jmin = model.V[:,k].argmin()\n",
    "    idmax = data.cindex[jmax]\n",
    "    idmin = data.cindex[jmin]\n",
    "    amax = data.get_anime_by_id(idmax)\n",
    "    amin = data.get_anime_by_id(idmin)\n",
    "    print(f'Feature {k}:  min : {amin.title}  max : {amax.title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo\n",
    "* Normalize scores and switch algorithm **or** implement bias terms.\n",
    "* Predict scores of users not in dataset.\n",
    "* Move loading dataset and training to functions.\n",
    "* REST Api: https://medium.com/@mahdi04/train-predict-simple-machine-learning-models-with-django-rest-76ce46bf2868"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Webscrape current animelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malscraper\n",
    "import importlib\n",
    "importlib.reload(malscraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myanimelist = malscraper.get_user_anime_list('Manuel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = userlist.index('Manuel')\n",
    "\n",
    "prediction = pd.Series(np.dot(W[index],H), index=anime_ids)\n",
    "watched = [a['id_ref'] for a in myanimelist if a['id_ref'] in prediction.index]\n",
    "prediction = prediction.drop(list(watched))  # Note: columns == anime_ids's\n",
    "\n",
    "for i in prediction.sort_values(ascending=False).head(10).index:\n",
    "    print(anime_dict[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animerec",
   "language": "python",
   "name": "animerec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
